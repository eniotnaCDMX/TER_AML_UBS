{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91b9c7cc",
   "metadata": {},
   "source": [
    "# Notebook 2 - Scenarios Rules based\n",
    "\n",
    "Notre objectif ici sera de construire puis d'optimiser des scénarios à \"règles explicites\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b00985b-4540-4172-aba6-ce41fe0092d2",
   "metadata": {},
   "source": [
    "### On importe les librairies necessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "158bbda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pymoo.algorithms.moo.nsga2 import NSGA2\n",
    "from pymoo.problems.functional import FunctionalProblem\n",
    "from pymoo.optimize import minimize\n",
    "from pymoo.operators.crossover.pntx import TwoPointCrossover\n",
    "from pymoo.operators.mutation.bitflip import BitflipMutation\n",
    "# For random sampling in NSGA-II\n",
    "from pymoo.operators.sampling.rnd import FloatRandomSampling\n",
    "# For\n",
    "from pymoo.operators.crossover.sbx import SBX\n",
    "# For\n",
    "from pymoo.operators.mutation.pm import PM\n",
    "from pymoo.util.nds.non_dominated_sorting import NonDominatedSorting\n",
    "\n",
    "import random\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0315701b-37df-412b-b3f5-81fe8f8e685c",
   "metadata": {},
   "source": [
    "### On importe les données nécessaires\n",
    "\n",
    "Les seules données dont on aura vraiment besoin ici est l'aggrégat que l'on a calculé dans le notebook 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "961d4af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"12M_trans/AML_features.csv\")\n",
    "\n",
    "features = [col for col in df.columns if col not in ['IS_FRAUD', 'ACCOUNT_ID']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ed8f26-d83e-4f85-ac2b-9d8b9c5184bb",
   "metadata": {},
   "source": [
    "### Paramètres utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3428d2da-076f-42e5-8fe8-bf0afe39b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_recall = 0.85\n",
    "training_size = 0.8\n",
    "rule_nb = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74841e6b-245f-4221-82c1-39a2233e41c9",
   "metadata": {},
   "source": [
    "### Création de fonctions que l'on utilisera par la suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd6ee080-efe2-4be5-a73a-d53c86c929c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(thresholds, rule_str, dataset):\n",
    "    \"\"\"\n",
    "    Calcule le rappel pour une règle donnée et un ensemble de thresholds.\n",
    "    \n",
    "    Parameters:\n",
    "    thresholds (list): Une liste de valeurs de seuils [threshold_1, threshold_2, ..., threshold_n].\n",
    "    rule_str (str): La règle à appliquer sous forme de chaîne de caractères. \n",
    "                    Les variables de seuil doivent être sous la forme R1, R2, etc.\n",
    "    dataset (pd.DataFrame): Le dataset sur lequel appliquer la règle.\n",
    "    \n",
    "    Returns:\n",
    "    float: Le rappel (recall) calculé.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(thresholds) != len(features):\n",
    "        raise ValueError(\"Le nombre de thresholds doit correspondre au nombre de colonnes pertinentes.\")\n",
    "\n",
    "    conditions = {\n",
    "        f'R{i+1}': f\"(dataset['{col}'] >= {thresholds[i]})\"\n",
    "        for i, col in enumerate(features)\n",
    "    }\n",
    "    \n",
    "    # Remplacer les placeholders R1, R2, etc., par les conditions réelles\n",
    "    #for key, condition in conditions.items():\n",
    "    #    rule_str = rule_str.replace(key, condition)\n",
    "        \n",
    "    # Replace placeholders with actual conditions, starting with the largest index\n",
    "    for key in sorted(conditions.keys(), key=lambda k: len(k), reverse=True):\n",
    "        rule_str = rule_str.replace(key, conditions[key])\n",
    "    \n",
    "    \n",
    "    # Appliquer la règle au dataset en utilisant eval\n",
    "    alerts = dataset[eval(rule_str)]\n",
    "    \n",
    "    # Calculer le nombre de fraudes détectées\n",
    "    num_fraud_alerts = alerts[alerts['IS_FRAUD'] == 1].shape[0]\n",
    "    total_sar = dataset[dataset['IS_FRAUD'] == 1].shape[0]\n",
    "    # Calculer le rappel\n",
    "    recall_value = num_fraud_alerts / total_sar\n",
    "    return recall_value\n",
    "\n",
    "\n",
    "\n",
    "def conversion_rate(thresholds, rule_str, dataset):\n",
    "    \"\"\"\n",
    "    Calcule le taux de conversion pour une règle donnée et un ensemble de thresholds.\n",
    "    \n",
    "    Parameters:\n",
    "    thresholds (list): Une liste de valeurs de seuils [threshold_1, threshold_2, ..., threshold_n].\n",
    "    rule_str (str): La règle à appliquer sous forme de chaîne de caractères. \n",
    "                    Les variables de seuil doivent être sous la forme R1, R2, etc.\n",
    "    dataset (pd.DataFrame): Le dataset sur lequel appliquer la règle.\n",
    "    \n",
    "    Returns:\n",
    "    float: Le taux de conversion calculé.\n",
    "    \"\"\"\n",
    "    \n",
    "    if len(thresholds) != len(features):\n",
    "        raise ValueError(\"Le nombre de thresholds doit correspondre au nombre de colonnes pertinentes.\")\n",
    "\n",
    "    conditions = {\n",
    "        f'R{i+1}': f\"(dataset['{col}'] >= {thresholds[i]})\"\n",
    "        for i, col in enumerate(features)\n",
    "    }\n",
    "    \n",
    "    # Remplacer les placeholders R1, R2, etc., par les conditions réelles\n",
    "    #for key, condition in conditions.items():\n",
    "    #    rule_str = rule_str.replace(key, condition)\n",
    "    \n",
    "    # Replace placeholders with actual conditions, starting with the largest index\n",
    "    for key in sorted(conditions.keys(), key=lambda k: len(k), reverse=True):\n",
    "        rule_str = rule_str.replace(key, conditions[key])\n",
    "    \n",
    "    \n",
    "    # Appliquer la règle au dataset en utilisant eval\n",
    "    alerts = dataset[eval(rule_str)]\n",
    "    \n",
    "    # Calculer le nombre total d'alertes\n",
    "    num_alerts = len(alerts)\n",
    "    \n",
    "    # Calculer le nombre de fraudes détectées\n",
    "    num_fraud_alerts = alerts[alerts['IS_FRAUD'] == 1].shape[0]\n",
    "\n",
    "    # Calculer le taux de conversion\n",
    "    conversion_rate_value = num_fraud_alerts / num_alerts if num_alerts > 0 else 0\n",
    "    \n",
    "    return conversion_rate_value\n",
    "\n",
    "\n",
    "def alert_volume(thresholds, rule_str, dataset):\n",
    "    if len(thresholds) != len(features):\n",
    "        raise ValueError(\"Le nombre de thresholds doit correspondre au nombre de colonnes pertinentes.\")\n",
    "\n",
    "    conditions = {\n",
    "        f'R{i+1}': f\"(dataset['{col}'] >= {thresholds[i]})\"\n",
    "        for i, col in enumerate(features)\n",
    "    }\n",
    "    \n",
    "    # Remplacer les placeholders R1, R2, etc., par les conditions réelles\n",
    "    #for key, condition in conditions.items():\n",
    "    #    rule_str = rule_str.replace(key, condition)\n",
    "    # Replace placeholders with actual conditions, starting with the largest index\n",
    "    for key in sorted(conditions.keys(), key=lambda k: len(k), reverse=True):\n",
    "        rule_str = rule_str.replace(key, conditions[key])\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Appliquer la règle au dataset en utilisant eval\n",
    "    alerts = dataset[eval(rule_str)]\n",
    "    \n",
    "    # Calculer le nombre total d'alertes\n",
    "    num_alerts = len(alerts)\n",
    "    \n",
    "    return num_alerts\n",
    "\n",
    "\n",
    "def generate_rules(df, n):\n",
    "    num_features = len(features)\n",
    "    rules = set()  # Using a set to ensure uniqueness\n",
    "    \n",
    "    # Start with the most restrictive rule (all AND)\n",
    "    base_rule = ' & '.join([f'R{i+1}' for i in range(num_features)])\n",
    "    rules.add(base_rule)\n",
    "\n",
    "    # Generate less restrictive rules by introducing OR operators\n",
    "    while len(rules) < n:\n",
    "        rule = list(f'R{i+1}' for i in range(num_features))\n",
    "        \n",
    "        # Decide how many ANDs we will keep (hardest rule has all ANDs)\n",
    "        num_ands = random.randint(1, max(1, num_features // 2))  # Less than half ANDs\n",
    "        \n",
    "        # Randomly replace some ANDs with ORs\n",
    "        for _ in range(num_features - num_ands):\n",
    "            idx = random.choice(range(len(rule) - 1))\n",
    "            rule[idx] = f'({rule[idx]} | {rule.pop(idx + 1)})'\n",
    "        \n",
    "        # Join the final rule\n",
    "        rule_str = ' & '.join(rule)\n",
    "        rules.add(rule_str)\n",
    "\n",
    "    return list(rules)\n",
    "\n",
    "\n",
    "def compute_pareto_front(points):\n",
    "    \"\"\"Computes the Pareto front from a set of points.\"\"\"\n",
    "    pareto_front = []\n",
    "    for i, point in enumerate(points):\n",
    "        dominated = False\n",
    "        for j, other in enumerate(points):\n",
    "            if i != j:\n",
    "                if all(other <= point) and any(other < point):\n",
    "                    dominated = True\n",
    "                    break\n",
    "        if not dominated:\n",
    "            pareto_front.append(point)\n",
    "    return np.array(pareto_front)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_thresholds(pareto_solutions, rule_str, train_set, test_set):\n",
    "    \"\"\"Evaluates recall and conversion rate for each threshold set on both train and test sets.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sol in pareto_solutions:\n",
    "        # Calculate metrics on the training set\n",
    "        train_recall = recall(sol, rule_str, train_set)\n",
    "        train_conversion_rate = conversion_rate(sol, rule_str, train_set)\n",
    "        \n",
    "        # Calculate metrics on the test set\n",
    "        test_recall = recall(sol, rule_str, test_set)\n",
    "        test_conversion_rate = conversion_rate(sol, rule_str, test_set)\n",
    "        \n",
    "        # Store the results\n",
    "        results.append({\n",
    "            'solution': sol,\n",
    "            'train_recall': train_recall,\n",
    "            'train_conversion_rate': train_conversion_rate,\n",
    "            'test_recall': test_recall,\n",
    "            'test_conversion_rate': test_conversion_rate\n",
    "        })\n",
    "    \n",
    "    # Sort by recall on the test set in descending order\n",
    "    results_sorted = sorted(results, key=lambda x: x['test_recall'], reverse=True)\n",
    "    \n",
    "    return results_sorted\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806dbf26",
   "metadata": {},
   "source": [
    "# 1 - Rule generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b93e30",
   "metadata": {},
   "source": [
    "### Génération des règles d'alerte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c38720e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rule 1: R1 & (R2 | (R3 | R4)) & R5 & (R6 | (R7 | ((R8 | R9) | R10))) & (R11 | (R12 | R13)) & ((R14 | (R15 | R16)) | (((R17 | R18) | ((R19 | R20) | (R21 | ((R22 | R23) | (R24 | R25))))) | R26))\n",
      "Rule 2: R1 & R2 & (R3 | R4) & (R5 | R6) & (R7 | (R8 | R9)) & (((R10 | R11) | R12) | R13) & R14 & R15 & R16 & (R17 | R18) & (R19 | R20) & (R21 | (R22 | R23)) & ((R24 | R25) | R26)\n",
      "Rule 3: (R1 | (R2 | (R3 | (R4 | R5)))) & R6 & R7 & (R8 | (R9 | R10)) & (R11 | R12) & (R13 | R14) & ((R15 | R16) | R17) & R18 & (R19 | R20) & (R21 | (R22 | R23)) & R24 & (R25 | R26)\n",
      "Rule 4: R1 & R2 & R3 & R4 & R5 & R6 & R7 & R8 & R9 & R10 & R11 & R12 & R13 & R14 & R15 & R16 & R17 & R18 & R19 & R20 & R21 & R22 & R23 & R24 & R25 & R26\n",
      "Rule 5: R1 & (((R2 | (R3 | R4)) | R5) | R6) & R7 & R8 & R9 & R10 & (R11 | R12) & ((R13 | R14) | R15) & (((R16 | R17) | R18) | R19) & ((R20 | R21) | R22) & R23 & ((R24 | R25) | R26)\n"
     ]
    }
   ],
   "source": [
    "rules = generate_rules(df, rule_nb)\n",
    "\n",
    "for i, rule in enumerate(rules, 1):\n",
    "    print(f\"Rule {i}: {rule}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51001951-31c0-419a-802a-70f0e48a661a",
   "metadata": {},
   "source": [
    "### Génération des jeux de données\n",
    "\n",
    "On utilise l'argument stratify pour être sûr que la proportion de SARs soit la même dans chaque set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b07d2ac-60a6-440a-966a-54908a544ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume X is your feature DataFrame and y is your target variable\n",
    "X = df[features]\n",
    "y = df[\"IS_FRAUD\"]\n",
    "\n",
    "# Step 1: Stratified split to create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=(1 - training_size), stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Step 2: Join the features and target for each set\n",
    "train_set = pd.concat([X_train, y_train], axis=1)\n",
    "test_set = pd.concat([X_test, y_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f313cc5d-0dc1-4628-a01a-4ffff4bb886b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df6914bb-82ee-4f7d-b8e2-41185c6751e9",
   "metadata": {},
   "source": [
    "# 2 - Bruteforce Tuning via méthode des pourcentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cf5c3a-6b8f-42d9-962e-0e9311f0b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_percentile_thresholds(dataset, features, percentiles):\n",
    "    \"\"\"Calculate the threshold values for each feature at given percentiles.\"\"\"\n",
    "    thresholds = {}\n",
    "    for feature in features:\n",
    "        thresholds[feature] = np.percentile(dataset[feature], percentiles[feature])\n",
    "    return thresholds\n",
    "\n",
    "\n",
    "# Initialize percentiles and thresholds\n",
    "percentiles = {feature: 1 for feature in features}\n",
    "thresholds_dict = calculate_percentile_thresholds(train_set, features, percentiles)\n",
    "\n",
    "# Convert thresholds from dictionary to list\n",
    "thresholds = [thresholds_dict[feature] for feature in features]\n",
    "\n",
    "for rule_str in rules[:1]:\n",
    "    while True:\n",
    "        can_update = False\n",
    "        for feature in features:\n",
    "            # Convert thresholds from dictionary to list before evaluating recall\n",
    "            thresholds = [thresholds_dict[feat] for feat in features]\n",
    "\n",
    "            current_recall = recall(thresholds, rule_str, train_set)\n",
    "            if current_recall < min_recall:\n",
    "                break  # Stop if recall is already below the limit\n",
    "\n",
    "            # Try incrementing the percentile for the current feature\n",
    "            if percentiles[feature] < 100:  # Ensure we're within bounds\n",
    "                new_percentiles = percentiles.copy()\n",
    "                new_percentiles[feature] += 1\n",
    "                new_thresholds_dict = calculate_percentile_thresholds(train_set, features, new_percentiles)\n",
    "\n",
    "                # Convert new_thresholds from dictionary to list\n",
    "                new_thresholds = [new_thresholds_dict[feat] for feat in features]\n",
    "\n",
    "                new_recall = recall(new_thresholds, rule_str, train_set)\n",
    "\n",
    "                if new_recall >= min_recall:\n",
    "                    percentiles = new_percentiles\n",
    "                    thresholds_dict = new_thresholds_dict\n",
    "                    can_update = True  # We made an update, so we continue the loop\n",
    "\n",
    "        if not can_update:\n",
    "            break  # Exit the loop if no further updates can be made\n",
    "\n",
    "    # Convert final thresholds from dictionary to list\n",
    "    thresholds = [thresholds_dict[feature] for feature in features]\n",
    "\n",
    "    # Evaluate the final thresholds on the test set\n",
    "    test_recall = recall(thresholds, rule_str, test_set)\n",
    "    test_conversion_rate = conversion_rate(thresholds, rule_str, test_set)\n",
    "\n",
    "    print(f\"Final thresholds: {thresholds_dict}\")\n",
    "    print(f\"Train Recall: {recall(thresholds, rule_str, train_set)}\")\n",
    "    print(f\"Test Recall: {test_recall}, Test Conversion Rate: {test_conversion_rate}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48e6b3c-6e4b-4a1f-b7dd-6fa1861a1df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the min_recall values to test\n",
    "min_recall_values = np.linspace(0.85, 0.99, num=15)\n",
    "\n",
    "# Initialize lists to store recall and conversion rate\n",
    "recall_list = []\n",
    "conversion_rate_list = []\n",
    "\n",
    "# Iterate over each min_recall value\n",
    "for min_recall in min_recall_values:\n",
    "    # Initialize percentiles and thresholds\n",
    "    percentiles = {feature: 1 for feature in features}\n",
    "    thresholds_dict = calculate_percentile_thresholds(train_set, features, percentiles)\n",
    "    \n",
    "    # Main loop for adjusting thresholds\n",
    "    for rule_str in rules[:1]:  # Assuming you are using only the first rule\n",
    "        while True:\n",
    "            can_update = False\n",
    "            for feature in features:\n",
    "                # Convert thresholds from dictionary to list before evaluating recall\n",
    "                thresholds = [thresholds_dict[feat] for feat in features]\n",
    "\n",
    "                current_recall = recall(thresholds, rule_str, train_set)\n",
    "                if current_recall < min_recall:\n",
    "                    break  # Stop if recall is already below the limit\n",
    "\n",
    "                # Try incrementing the percentile for the current feature\n",
    "                if percentiles[feature] < 100:  # Ensure we're within bounds\n",
    "                    new_percentiles = percentiles.copy()\n",
    "                    new_percentiles[feature] += 1\n",
    "                    new_thresholds_dict = calculate_percentile_thresholds(train_set, features, new_percentiles)\n",
    "\n",
    "                    # Convert new_thresholds from dictionary to list\n",
    "                    new_thresholds = [new_thresholds_dict[feat] for feat in features]\n",
    "\n",
    "                    new_recall = recall(new_thresholds, rule_str, train_set)\n",
    "\n",
    "                    if new_recall >= min_recall:\n",
    "                        percentiles = new_percentiles\n",
    "                        thresholds_dict = new_thresholds_dict\n",
    "                        can_update = True  # We made an update, so we continue the loop\n",
    "\n",
    "            if not can_update:\n",
    "                break  # Exit the loop if no further updates can be made\n",
    "\n",
    "        # Convert final thresholds from dictionary to list\n",
    "        thresholds = [thresholds_dict[feature] for feature in features]\n",
    "\n",
    "        # Evaluate the final thresholds on the test set\n",
    "        test_recall = recall(thresholds, rule_str, test_set)\n",
    "        test_conversion_rate = conversion_rate(thresholds, rule_str, test_set)\n",
    "        \n",
    "        # Store the recall and conversion rate\n",
    "        recall_list.append(min_recall)\n",
    "        conversion_rate_list.append(test_conversion_rate)\n",
    "\n",
    "# Plot Recall vs. Conversion Rate\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall_list, conversion_rate_list, marker='o')\n",
    "plt.title('Recall vs. Conversion Rate')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Conversion Rate')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b59c94c-3827-4163-8585-c7be54a89ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the min_recall values to test\n",
    "min_recall_values = np.linspace(0.85, 0.99, num=15)\n",
    "\n",
    "# Initialize lists to store recall and conversion rate\n",
    "recall_list = []\n",
    "conversion_rate_list = []\n",
    "\n",
    "# Iterate over each min_recall value\n",
    "for min_recall in min_recall_values:\n",
    "    print(f\"Starting optimization for min_recall: {min_recall:.2f}\")\n",
    "    \n",
    "    # Initialize percentiles and thresholds\n",
    "    percentiles = {feature: 1 for feature in features}\n",
    "    thresholds_dict = calculate_percentile_thresholds(train_set, features, percentiles)\n",
    "    \n",
    "    # Main loop for adjusting thresholds\n",
    "    for rule_str in rules[:1]:  # Assuming you are using only the first rule\n",
    "        while True:\n",
    "            can_update = False\n",
    "            for feature in features:\n",
    "                # Convert thresholds from dictionary to list before evaluating recall\n",
    "                thresholds = [thresholds_dict[feat] for feat in features]\n",
    "\n",
    "                current_recall = recall(thresholds, rule_str, train_set)\n",
    "                if current_recall < min_recall:\n",
    "\n",
    "                    break  # Stop if recall is already below the limit\n",
    "\n",
    "                # Try incrementing the percentile for the current feature\n",
    "                if percentiles[feature] < 100:  # Ensure we're within bounds\n",
    "                    new_percentiles = percentiles.copy()\n",
    "                    new_percentiles[feature] += 1\n",
    "                    new_thresholds_dict = calculate_percentile_thresholds(train_set, features, new_percentiles)\n",
    "\n",
    "                    # Convert new_thresholds from dictionary to list\n",
    "                    new_thresholds = [new_thresholds_dict[feat] for feat in features]\n",
    "\n",
    "                    new_recall = recall(new_thresholds, rule_str, train_set)\n",
    "\n",
    "                    if new_recall >= min_recall:\n",
    "                        percentiles = new_percentiles\n",
    "                        thresholds_dict = new_thresholds_dict\n",
    "                        can_update = True  # We made an update, so we continue the loop\n",
    "\n",
    "\n",
    "            if not can_update:\n",
    "\n",
    "                break  # Exit the loop if no further updates can be made\n",
    "\n",
    "        # Convert final thresholds from dictionary to list\n",
    "        thresholds = [thresholds_dict[feature] for feature in features]\n",
    "\n",
    "        # Evaluate the final thresholds on the test set\n",
    "        test_recall = recall(thresholds, rule_str, test_set)\n",
    "        test_conversion_rate = conversion_rate(thresholds, rule_str, test_set)\n",
    "        \n",
    "        # Store the recall and conversion rate\n",
    "        recall_list.append(min_recall)\n",
    "        conversion_rate_list.append(test_conversion_rate)\n",
    "        \n",
    "        # Print final results for this min_recall\n",
    "        print(f\"Test results for min_recall {min_recall:.2f}: Test Recall = {test_recall:.4f}, Test Conversion Rate = {test_conversion_rate:.4f}\")\n",
    "\n",
    "# Plot Recall vs. Conversion Rate\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(recall_list, conversion_rate_list, marker='o')\n",
    "plt.title('Recall vs. Conversion Rate')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Conversion Rate')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aafc76-1b44-45fe-978f-74cac86b916a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6381b3-51da-4a2d-a860-f9d9f034909c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9dfe1b52-9c94-4a37-ac44-da537169f3e2",
   "metadata": {},
   "source": [
    "# 3 - Tuning via algorithme génétique d'optimisation bi-objectif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfbf363e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "n_gen  |  n_eval  | n_nds  |     cv_min    |     cv_avg    |      eps      |   indicator  \n",
      "==========================================================================================\n",
      "     1 |      100 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n",
      "     2 |      200 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n",
      "     3 |      300 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n",
      "     4 |      400 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n",
      "     5 |      500 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n",
      "     6 |      600 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n",
      "     7 |      700 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n",
      "     8 |      800 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n",
      "     9 |      900 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n",
      "    10 |     1000 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n",
      "    11 |     1100 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n",
      "    12 |     1200 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n",
      "    13 |     1300 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n",
      "    14 |     1400 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n",
      "    15 |     1500 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n",
      "    16 |     1600 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n",
      "    17 |     1700 |      1 |  0.8500000000 |  0.8500000000 |             - |             -\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Define the problem using FunctionalProblem\u001b[39;00m\n\u001b[0;32m     14\u001b[0m problem_train \u001b[38;5;241m=\u001b[39m FunctionalProblem(\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Nombre de features\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     n_var\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(features),  \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     xu\u001b[38;5;241m=\u001b[39mxu\n\u001b[0;32m     24\u001b[0m )\n\u001b[1;32m---> 26\u001b[0m res_train \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_criteria\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Extract Pareto optimal solutions\u001b[39;00m\n\u001b[0;32m     29\u001b[0m pareto_solutions_train \u001b[38;5;241m=\u001b[39m res_train\u001b[38;5;241m.\u001b[39mX\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymoo\\optimize.py:67\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(problem, algorithm, termination, copy_algorithm, copy_termination, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m     algorithm\u001b[38;5;241m.\u001b[39msetup(problem, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;66;03m# actually execute the algorithm\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# store the deep copied algorithm in the result object\u001b[39;00m\n\u001b[0;32m     70\u001b[0m res\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m=\u001b[39m algorithm\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymoo\\core\\algorithm.py:138\u001b[0m, in \u001b[0;36mAlgorithm.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_next():\n\u001b[1;32m--> 138\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymoo\\core\\algorithm.py:158\u001b[0m, in \u001b[0;36mAlgorithm.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# call the advance with them after evaluation\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m infills \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfills\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(infills\u001b[38;5;241m=\u001b[39minfills)\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# if the algorithm does not follow the infill-advance scheme just call advance\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymoo\\core\\evaluator.py:69\u001b[0m, in \u001b[0;36mEvaluator.eval\u001b[1;34m(self, problem, pop, skip_already_evaluated, evaluate_values_of, count_evals, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# evaluate the solutions (if there are any)\u001b[39;00m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(I) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     67\u001b[0m \n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# do the actual evaluation - call the sub-function to set the corresponding values to the population\u001b[39;00m\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval(problem, pop[I], evaluate_values_of, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# update the function evaluation counter\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count_evals:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymoo\\core\\evaluator.py:90\u001b[0m, in \u001b[0;36mEvaluator._eval\u001b[1;34m(self, problem, pop, evaluate_values_of, **kwargs)\u001b[0m\n\u001b[0;32m     87\u001b[0m X \u001b[38;5;241m=\u001b[39m pop\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     89\u001b[0m \u001b[38;5;66;03m# call the problem to evaluate the solutions\u001b[39;00m\n\u001b[1;32m---> 90\u001b[0m out \u001b[38;5;241m=\u001b[39m problem\u001b[38;5;241m.\u001b[39mevaluate(X, return_values_of\u001b[38;5;241m=\u001b[39mevaluate_values_of, return_as_dictionary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;66;03m# for each of the attributes set it to the problem\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m out\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymoo\\core\\problem.py:257\u001b[0m, in \u001b[0;36mProblem.evaluate\u001b[1;34m(self, X, return_values_of, return_as_dictionary, *args, **kwargs)\u001b[0m\n\u001b[0;32m    254\u001b[0m     only_single_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, np\u001b[38;5;241m.\u001b[39mndarray))\n\u001b[0;32m    256\u001b[0m \u001b[38;5;66;03m# this is where the actual evaluation takes place\u001b[39;00m\n\u001b[1;32m--> 257\u001b[0m _out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo(X, return_values_of, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    259\u001b[0m out \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    260\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _out\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    261\u001b[0m \n\u001b[0;32m    262\u001b[0m     \u001b[38;5;66;03m# copy it to a numpy array (it might be one of jax at this point)\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymoo\\core\\problem.py:297\u001b[0m, in \u001b[0;36mProblem.do\u001b[1;34m(self, X, return_values_of, *args, **kwargs)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# do the function evaluation\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melementwise:\n\u001b[1;32m--> 297\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_elementwise(X, out, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_vectorized(X, out, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymoo\\core\\problem.py:315\u001b[0m, in \u001b[0;36mProblem._evaluate_elementwise\u001b[1;34m(self, X, out, *args, **kwargs)\u001b[0m\n\u001b[0;32m    312\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melementwise_func(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[0;32m    314\u001b[0m \u001b[38;5;66;03m# execute the runner\u001b[39;00m\n\u001b[1;32m--> 315\u001b[0m elems \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melementwise_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# for each evaluation call\u001b[39;00m\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m elems:\n\u001b[0;32m    319\u001b[0m \n\u001b[0;32m    320\u001b[0m     \u001b[38;5;66;03m# for each key stored for this evaluation\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymoo\\core\\problem.py:32\u001b[0m, in \u001b[0;36mLoopedElementwiseEvaluation.__call__\u001b[1;34m(self, f, X)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, X):\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [f(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymoo\\core\\problem.py:32\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, X):\n\u001b[1;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymoo\\core\\problem.py:25\u001b[0m, in \u001b[0;36mElementwiseEvaluationFunction.__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     24\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m---> 25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem\u001b[38;5;241m.\u001b[39m_evaluate(x, out, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymoo\\problems\\functional.py:40\u001b[0m, in \u001b[0;36mFunctionalProblem._evaluate\u001b[1;34m(self, x, out, *args, **kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, out, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     39\u001b[0m     out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([obj(x) \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjs])\n\u001b[1;32m---> 40\u001b[0m     out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([constr(x) \u001b[38;5;28;01mfor\u001b[39;00m constr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstr_ieq])\n\u001b[0;32m     41\u001b[0m     out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([constr(x) \u001b[38;5;28;01mfor\u001b[39;00m constr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstr_eq])\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pymoo\\problems\\functional.py:40\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_evaluate\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, out, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     39\u001b[0m     out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([obj(x) \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjs])\n\u001b[1;32m---> 40\u001b[0m     out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mG\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mconstr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m constr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstr_ieq])\n\u001b[0;32m     41\u001b[0m     out[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mH\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([constr(x) \u001b[38;5;28;01mfor\u001b[39;00m constr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconstr_eq])\n",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     11\u001b[0m xu \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([train_set[col]\u001b[38;5;241m.\u001b[39mmax() \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m features])\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Define the problem using FunctionalProblem\u001b[39;00m\n\u001b[0;32m     14\u001b[0m problem_train \u001b[38;5;241m=\u001b[39m FunctionalProblem(\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;66;03m# Nombre de features\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     n_var\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(features),  \n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Définition des objectifs\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# On ajoute un moins devant chaque fonction car pymoo ne peut que minimiser, et non maximiser.\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     objs\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m-\u001b[39mconversion_rate(x, rule_str, train_set), \n\u001b[0;32m     20\u001b[0m           \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m-\u001b[39mrecall(x, rule_str, train_set)],\n\u001b[1;32m---> 21\u001b[0m     constr_ieq\u001b[38;5;241m=\u001b[39m[\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;241m-\u001b[39m(\u001b[43mrecall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrule_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m min_recall)], \n\u001b[0;32m     22\u001b[0m     xl\u001b[38;5;241m=\u001b[39mxl,\n\u001b[0;32m     23\u001b[0m     xu\u001b[38;5;241m=\u001b[39mxu\n\u001b[0;32m     24\u001b[0m )\n\u001b[0;32m     26\u001b[0m res_train \u001b[38;5;241m=\u001b[39m minimize(problem_train, algorithm, stop_criteria, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Extract Pareto optimal solutions\u001b[39;00m\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mrecall\u001b[1;34m(thresholds, rule_str, dataset)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Calculer le nombre de fraudes détectées\u001b[39;00m\n\u001b[0;32m     36\u001b[0m num_fraud_alerts \u001b[38;5;241m=\u001b[39m alerts[alerts[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIS_FRAUD\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m---> 37\u001b[0m total_sar \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mIS_FRAUD\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Calculer le rappel\u001b[39;00m\n\u001b[0;32m     39\u001b[0m recall_value \u001b[38;5;241m=\u001b[39m num_fraud_alerts \u001b[38;5;241m/\u001b[39m total_sar\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3796\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3794\u001b[0m \u001b[38;5;66;03m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   3795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m com\u001b[38;5;241m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 3796\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_bool_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3798\u001b[0m \u001b[38;5;66;03m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   3799\u001b[0m \u001b[38;5;66;03m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   3800\u001b[0m is_single_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(key)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3850\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3847\u001b[0m \u001b[38;5;66;03m# check_bool_indexer will throw exception if Series key cannot\u001b[39;00m\n\u001b[0;32m   3848\u001b[0m \u001b[38;5;66;03m# be reindexed to match DataFrame rows\u001b[39;00m\n\u001b[0;32m   3849\u001b[0m key \u001b[38;5;241m=\u001b[39m check_bool_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, key)\n\u001b[1;32m-> 3850\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[43mkey\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnonzero\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   3851\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_take_with_is_copy(indexer, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the algorithm\n",
    "algorithm = NSGA2(pop_size=100,\n",
    "                  sampling= FloatRandomSampling(),\n",
    "                  crossover= SBX(prob_var=0.9, eta=20, prob_exch=1.0),\n",
    "                  mutation= PM(eta=20),\n",
    "                  eliminate_duplicates= True)\n",
    "\n",
    "# Define the stopping criterion\n",
    "stop_criteria = ('n_gen', 100)\n",
    "\n",
    "for rule_str in rules[:1]:\n",
    "    \n",
    "    ##############################################################################\n",
    "    ####################### Phase d'entrainement #################################\n",
    "    ##############################################################################\n",
    "    \n",
    "    # On créé les bornes inférieures du problème\n",
    "    xl = np.array([train_set[col].min() for col in features])\n",
    "\n",
    "    # On crée les bornes supérieures du problème.\n",
    "    xu = np.array([train_set[col].max() for col in features])\n",
    "\n",
    "    # Define the problem using FunctionalProblem\n",
    "    problem_train = FunctionalProblem(\n",
    "        # Nombre de features\n",
    "        n_var=len(features),  \n",
    "        # Définition des objectifs\n",
    "        # On ajoute un moins devant chaque fonction car pymoo ne peut que minimiser, et non maximiser.\n",
    "        objs=[lambda x: -conversion_rate(x, rule_str, train_set), \n",
    "              lambda x: -recall(x, rule_str, train_set)],\n",
    "        constr_ieq=[lambda x: -(recall(x, rule_str, train_set) - min_recall)], \n",
    "        xl=xl,\n",
    "        xu=xu\n",
    "    )\n",
    "\n",
    "    res_train = minimize(problem_train, algorithm, stop_criteria, seed=1, verbose=True)\n",
    "\n",
    "    # Extract Pareto optimal solutions\n",
    "    pareto_solutions_train = res_train.X\n",
    "    pareto_objectives_train = res_train.F\n",
    "    \n",
    "    # Evaluate each Pareto solution on the test set\n",
    "    pareto_objectives_test = []\n",
    "    for sol in pareto_solutions_train:\n",
    "        test_conversion_rate = conversion_rate(sol, rule_str, test_set)\n",
    "        test_recall = recall(sol, rule_str, test_set)\n",
    "        pareto_objectives_test.append([-test_conversion_rate, -test_recall])  # Note the negative for minimization\n",
    "    \n",
    "    pareto_objectives_test = np.array(pareto_objectives_test)\n",
    "    \n",
    "    # Compute the Pareto front on the test set manually\n",
    "    pareto_front_test = compute_pareto_front(pareto_objectives_test)\n",
    "\n",
    "    # Plotting the Pareto fronts\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Training Pareto front\n",
    "    plt.scatter(-pareto_objectives_train[:, 0], -pareto_objectives_train[:, 1], color='blue', label='Train Pareto Front')\n",
    "    \n",
    "    # Test Pareto front\n",
    "    if len(pareto_front_test) > 0:\n",
    "        plt.scatter(-pareto_front_test[:, 0], -pareto_front_test[:, 1], color='red', label='Test Pareto Front')\n",
    "    \n",
    "    plt.title(f'Pareto Fronts for Rule: {rule_str}')\n",
    "    plt.xlabel('Conversion Rate')\n",
    "    plt.ylabel('Recall')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c883b727",
   "metadata": {},
   "source": [
    "## Define the stop criterion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdb0393",
   "metadata": {},
   "source": [
    "## Run the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee895152",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
